{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5b4d5f",
   "metadata": {},
   "source": [
    "# Notebook 3 - Annotation of highly connected metabolomic feature communities.\n",
    "\n",
    "#### This notebook is a part of a project with the Center for Systems Biology at the University of Iceland. Here, the goal is to run the features from the metabolomic dataset through an automatic annotation procedure using a custom-made function. Then, the putative annotation is used to remove any un-annotated communities from any further downstream analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64691ab1",
   "metadata": {},
   "source": [
    "## Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "acea4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_unknown_mz_values_with_adducts(unknown_mz_dict, known_mz_metabolite_dict, adduct_df, ppm_threshold=5):\n",
    "    matched_results = {}\n",
    "\n",
    "    for unknown_mz, tupp in unknown_mz_dict.items():\n",
    "        ion_mode = tupp[1]\n",
    "        orig_name = tupp[0]\n",
    "        matched_results[unknown_mz] = []\n",
    "\n",
    "        for adduct_row in adduct_df.itertuples(index=False):\n",
    "            adduct, adduct_mass, adduct_ion_mode,multiply_val = adduct_row[0], adduct_row[1], adduct_row[2],adduct_row[3]\n",
    "            if multiply_val == 1:\n",
    "                mass_to_check = unknown_mz - adduct_mass\n",
    "            elif multiply_val == 2:\n",
    "                mass_to_check = np.divide((unknown_mz - adduct_mass),multiply_val)\n",
    "            if ion_mode == adduct_ion_mode:\n",
    "                for known_mz, metabolite_id in known_mz_metabolite_dict.items():\n",
    "                    ppm_difference = abs(mass_to_check - known_mz) / abs(known_mz) * 1e6\n",
    "                    if ppm_difference <= ppm_threshold: \n",
    "                        matched_results[unknown_mz].append((metabolite_id, orig_name,adduct, ion_mode, ppm_difference))\n",
    "\n",
    "\n",
    "    return matched_results\n",
    "\n",
    "def match_unknown_mz_values_with_metabolite_ids(unknown_mz_dict, known_mz_metabolite_dict, adduct_df, id_to_name_dict, ppm_threshold=5):\n",
    "    \n",
    "    # Match unknown masses with adducts:\n",
    "    resss = match_unknown_mz_values_with_adducts(unknown_mz_dict, known_mz_metabolite_dict, adduct_df,ppm_threshold)\n",
    "\n",
    "    # Create an empty DataFrame\n",
    "    columns = ['unknown_mz', 'metabolite_id','feature', 'adduct','ionization','mass_diff']\n",
    "    df_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Populate the DataFrame\n",
    "    for unknown_mz, matches in resss.items():\n",
    "        for match in matches:\n",
    "            if isinstance(match, list):\n",
    "                for metabolite_id in match:\n",
    "                    df_results = pd.concat([df_results, pd.DataFrame({\n",
    "                        'unknown_mz': [unknown_mz],\n",
    "                        'metabolite_id': [metabolite_id],\n",
    "                        'feature':[match[1]],\n",
    "                        'adduct': [match[2]],\n",
    "                        'ionization':[match[3]],\n",
    "                        'mass_diff':[match[4]],\n",
    "\n",
    "\n",
    "                    })], ignore_index=True)\n",
    "            else:\n",
    "                df_results = pd.concat([df_results, pd.DataFrame({\n",
    "                    'unknown_mz': [unknown_mz],\n",
    "                    'metabolite_id': [match[0]],\n",
    "                    'feature':[match[1]],\n",
    "                    'adduct': [match[2]],\n",
    "                    'ionization':[match[3]],\n",
    "                    'mass_diff':[match[4]],\n",
    "                })], ignore_index=True)\n",
    "\n",
    "    def get_dict_value(key):\n",
    "        return id_to_name_dict.get(key, None)            \n",
    "\n",
    "    # Use explode to expand lists\n",
    "    df_results = df_results.explode('metabolite_id').reset_index(drop = True)\n",
    "\n",
    "    # Find matching kegg ids:\n",
    "    df_results['metabolite_name'] = df_results['metabolite_id'].apply(get_dict_value)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def annotate_module_degree(expression_data,module_membership_data,df_modules,all_info_dat,df_mapped_metabolites,module_of_interest):\n",
    "    \n",
    "    '''\n",
    "    This function summarises a module of interest with all the relevant data (features, mapped mets, adduts, rt, metabolite name)\n",
    "    '''\n",
    "    # m.z values:\n",
    "    m_z = [float(x.split('_')[-1]) for x in expression_data.index.tolist()]\n",
    "    \n",
    "    # retention time:\n",
    "    rt_dict = dict(zip(all_info_dat['mz_name'],all_info_dat['rt']))\n",
    "    rt_vals = [rt_dict[x] for x in expression_data.index.tolist()]\n",
    "    \n",
    "    # Get p-values (0.049 when features are associated with module of interest)\n",
    "    p_vals = np.ones(expression_data.shape[0])\n",
    "    p_vals[df_modules[df_modules['Module']==int(module_of_interest)].index.tolist()] = 0.049\n",
    "    \n",
    "    # Get the membership values sorted:\n",
    "    corr_vals = module_membership_data.loc[:,int(module_of_interest)]\n",
    "    degree_vals = df_modules['Weighted.degree']\n",
    "\n",
    "    outp_dataf = pd.DataFrame([expression_data.index.tolist(),m_z,rt_vals,corr_vals,degree_vals,p_vals]).T\n",
    "    outp_dataf.columns = ['feature','m.z','r.t','corr.to.eigenvector','weighted.degree','p.value']\n",
    "    \n",
    "    # Now get matched \"hits\" from the metabolite dataframe:\n",
    "    outp_dataf = pd.merge(outp_dataf, df_mapped_metabolites, on='feature', how='left')\n",
    "\n",
    "    # Sort based on p-value:\n",
    "    outp_dataf = outp_dataf.sort_values(by=['p.value','weighted.degree'],ascending=[True, False]).reset_index(drop = True)\n",
    "    \n",
    "    # Drop non-hitters:\n",
    "    outp_dataf = outp_dataf.dropna(subset = ['metabolite_name'],axis = 0).reset_index(drop = True)\n",
    "    \n",
    "    # Drop the unknown_mz:\n",
    "    outp_dataf = outp_dataf.drop(['unknown_mz'],axis = 1)\n",
    "    return outp_dataf\n",
    "\n",
    "def get_subset_pathways(annotated_module,pathbank_data,hmdb_or_kegg = 'HMDB'):\n",
    "    \n",
    "    '''\n",
    "    This function creates a pathway dictionary where each pathway that is putatively annotated within a module\n",
    "    maps to all its associated metabolite ids from pathbank data.\n",
    "    '''\n",
    "    \n",
    "    dattt_subset = annotated_module[annotated_module['p.value'] < 0.05]\n",
    "    if hmdb_or_kegg == 'HMDB':\n",
    "        dat_subset = pathbank_data[pathbank_data['HMDB ID'].isin(dattt_subset['metabolite_id'].unique())].reset_index(drop = True)\n",
    "        # Create a pathway dictionary:\n",
    "        pathway_dict = {}\n",
    "\n",
    "        # Use groupby to create a dictionary of pathway-metabolite associations\n",
    "        pathway_dict = {group: data['HMDB ID'].tolist() for group, data in dat_subset.groupby('Pathway Name')}\n",
    "    elif hmdb_or_kegg == 'KEGG':\n",
    "        dat_subset = pathbank_data[pathbank_data['KEGG ID'].isin(dattt_subset['metabolite_id'].unique())].reset_index(drop = True)\n",
    "        # Create a pathway dictionary:\n",
    "        pathway_dict = {}\n",
    "\n",
    "        # Use groupby to create a dictionary of pathway-metabolite associations\n",
    "        pathway_dict = {group: data['KEGG ID'].tolist() for group, data in dat_subset.groupby('Pathway Name')}\n",
    "\n",
    "    # Drop pathways that have less than 3 metabolite identifiers\n",
    "    to_drop = []\n",
    "    for key,val in pathway_dict.items():\n",
    "        if len(val) < 1:\n",
    "            to_drop.append(key)\n",
    "\n",
    "    for pathway in to_drop:\n",
    "        del pathway_dict[pathway]\n",
    "    return pathway_dict\n",
    "\n",
    "\n",
    "def pathway_enrichment_analysis(annotated_module,pathbank_data,hmdb_or_kegg = 'HMDB'):\n",
    "    \n",
    "    # START BY REMOVING SERINE FROM ANNOTATED MODULE:\n",
    "    annotated_module = annotated_module[annotated_module['metabolite_id'] != 'HMDB0000187'].reset_index()\n",
    "    \n",
    "    # Assuming 'merged_df2' is your DataFrame with features and associated pathways\n",
    "    if hmdb_or_kegg == 'HMDB':\n",
    "        df_results2 = annotated_module.rename(columns = {'metabolite_id':'HMDB ID'})\n",
    "        merged_df = pd.merge(df_results2, pathbank_data[['HMDB ID', 'Pathway Name']], on='HMDB ID', how='left')\n",
    "        #print(merged_df)\n",
    "    elif hmdb_or_kegg == 'KEGG':\n",
    "        df_results2 = annotated_module.rename(columns = {'metabolite_id':'KEGG ID'})\n",
    "        merged_df = pd.merge(df_results2, pathbank_data[['KEGG ID', 'Pathway Name']], on='KEGG ID', how='left')\n",
    "    \n",
    "    merged_df2 = merged_df.groupby('feature',sort = False)['Pathway Name'].apply(lambda x: [item for item in x if pd.notna(item)]).reset_index(name='pathways')\n",
    "    df = merged_df2.copy()\n",
    "    \n",
    "    # List of pathways for analysis (Only do the ones that map to the hits of interest):\n",
    "    pat_dict = get_subset_pathways(annotated_module,pathbank_data,hmdb_or_kegg = hmdb_or_kegg)\n",
    "    #print(pat_dict)\n",
    "    #print(len(pat_dict))\n",
    "    if not pat_dict:\n",
    "        print('Pathway dictionary is empty - no analysis is possible')\n",
    "        results_df = pd.DataFrame()\n",
    "        \n",
    "    else:\n",
    "        print('Annotating', len(pat_dict),'pathways...')\n",
    "        pathways_to_test = list(pat_dict.keys())\n",
    "\n",
    "        # DataFrame to store results\n",
    "        results_list = []\n",
    "\n",
    "        # Number of permutations for testing\n",
    "        num_permutations = 1000\n",
    "\n",
    "        # Specify the subset of features for analysis\n",
    "        selected_features = list(np.unique(annotated_module[annotated_module['p.value'] < 0.05]['feature'].values))\n",
    "        all_features = list(np.unique(annotated_module['feature'].values))\n",
    "\n",
    "        for selected_pathway in pathways_to_test:\n",
    "\n",
    "            # Observed count of selected pathway in the subset of features\n",
    "            observed_count = np.sum(df[df['feature'].isin(selected_features)].apply(lambda x: selected_pathway in x['pathways'], axis=1))\n",
    "            total_count_in_df = np.sum(df[df['feature'].isin(all_features)].apply(lambda x: selected_pathway in x['pathways'], axis=1))\n",
    "\n",
    "            # Perform permutation testing\n",
    "            permutation_counts = []\n",
    "            for _ in range(num_permutations):\n",
    "                # Shuffle the labels of the entire dataset\n",
    "                shuffled_labels = np.random.permutation(df.index)\n",
    "                #print(_)\n",
    "\n",
    "                # Count the occurrences of the selected pathway in the shuffled labels\n",
    "                shuffled_count = sum(df.loc[shuffled_labels[:len(selected_features)]].apply(lambda x: selected_pathway in x['pathways'], axis=1))\n",
    "                permutation_counts.append(shuffled_count)\n",
    "\n",
    "            # Calculate p-value based on permutation results\n",
    "            p_value = (np.sum(np.array(permutation_counts) >= observed_count) + 1) / (num_permutations + 1)\n",
    "            \n",
    "            # Append results to the list\n",
    "            results_list.append({\n",
    "                'pathway': selected_pathway,\n",
    "                'observed_count': observed_count,\n",
    "                'observed_ratio':observed_count/total_count_in_df,\n",
    "                'permutation_p.value': p_value,\n",
    "            })\n",
    "\n",
    "        # Convert the list to a DataFrame\n",
    "        results_df = pd.DataFrame(results_list)\n",
    "        results_df = results_df.sort_values(by = ['permutation_p.value'],ascending = [True]).reset_index(drop = True)\n",
    "    return results_df\n",
    "    \n",
    "def create_accumulated_dict(series1,series2):\n",
    "    out_dict = {}\n",
    "    for indexx,element in enumerate(series1):\n",
    "        if element not in out_dict:\n",
    "            out_dict[element] = [series2[indexx]]\n",
    "        else:\n",
    "            out_dict[element].append(series2[indexx])\n",
    "    return out_dict\n",
    "\n",
    "def trim_module_dataframe_and_find_representative_features(eigendf,expression_data,correlation_df,df_modules,all_info,mz_to_mets):\n",
    "    mods_to_remove = []\n",
    "    module_dictionary_features = {}\n",
    "    for modd in eigendf.columns.tolist():\n",
    "        #print(modd)\n",
    "        ann_mod = annotate_module_degree(expression_data,correlation_df,df_modules,all_info,mz_to_mets,modd)\n",
    "        ann_mod = ann_mod[ann_mod['p.value'] < 1]\n",
    "        values_to_find = ['M - H','M + H','M + Na','M - H2O + H','M + H2O - H','M + H2O + H','M - H2O - H']\n",
    "        first_occurrence_index = ann_mod[ann_mod['adduct'].isin(values_to_find)].index.min()\n",
    "        print('Module',modd)\n",
    "        # Check if any of the values were found\n",
    "        if pd.notna(first_occurrence_index):\n",
    "            print(first_occurrence_index)\n",
    "            chosen_feature = ann_mod.loc[first_occurrence_index,'feature']\n",
    "            print(ann_mod.loc[first_occurrence_index,['feature','metabolite_name']].values)\n",
    "            module_dictionary_features[modd] = chosen_feature\n",
    "        else:\n",
    "            mods_to_remove.append(modd)\n",
    "            print(f\"None of the specified values were found in the specified column.\")\n",
    "    return module_dictionary_features,mods_to_remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc9494d",
   "metadata": {},
   "source": [
    "## Annotation.\n",
    "\n",
    "#### One can either use HMDB or KEGG for annotating unknown compounds. In this script, we will use HMDB. \n",
    "\n",
    "#### Load the PathBank database containing multiple metabolite identifiers mapping to pathways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737a1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathbank_dat = pd.read_csv('pathbank_all_metabolites.csv')\n",
    "\n",
    "# Use only the human pathways:\n",
    "pathbank_dat = pathbank_dat[pathbank_dat['Species'] == 'Homo sapiens'].reset_index(drop = True)\n",
    "\n",
    "# Use only the metabolic pathway objects:\n",
    "pathbank_dat = pathbank_dat[pathbank_dat['Pathway Subject'] == 'Metabolic'].reset_index(drop = True)\n",
    "\n",
    "# Strip whitespace from the \"KEGG ID\" column\n",
    "pathbank_dat['KEGG ID'] = pathbank_dat['KEGG ID'].str.strip()\n",
    "pathbank_dat['HMDB ID'] = pathbank_dat['HMDB ID'].str.strip()\n",
    "\n",
    "# Remove rows with NaN values\n",
    "pathbank_dat = pathbank_dat.dropna(subset = ['KEGG ID'],axis = 0)\n",
    "\n",
    "# Create a dictionary that maps KEGG ids to metabolite names (useful later):\n",
    "kegg_dict = dict(zip(pathbank_dat['KEGG ID'],pathbank_dat['Metabolite Name']))\n",
    "hmdb_dict = dict(zip(pathbank_dat['HMDB ID'],pathbank_dat['Metabolite Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3a3d77",
   "metadata": {},
   "source": [
    "## Load the HMDB database to be able to scan and compare the unknown m/z values to known masses of HMDB compounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc997dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigur\\AppData\\Local\\Temp\\ipykernel_13120\\2119306765.py:1: DtypeWarning: Columns (6,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  hmdb = pd.read_csv('hmdb.csv')\n"
     ]
    }
   ],
   "source": [
    "hmdb = pd.read_csv('hmdb.csv')\n",
    "hmdb['name'] = hmdb['name'].apply(lambda x: x[2:-1])\n",
    "\n",
    "# Generate the mass_to_kegg dict from the hmdb database:\n",
    "mass_to_kegg_dict = {}\n",
    "\n",
    "for index, row in hmdb.iterrows():\n",
    "    mass = row['monisotopic_molecular_weight']\n",
    "    kegg_id = row['kegg']\n",
    "\n",
    "    if mass not in mass_to_kegg_dict:\n",
    "        mass_to_kegg_dict[mass] = []\n",
    "\n",
    "    mass_to_kegg_dict[mass].append(kegg_id)\n",
    "\n",
    "mass_to_kegg_dict = {mass: [kegg_id for kegg_id in kegg_ids if pd.notna(kegg_id)]\n",
    "                    for mass, kegg_ids in mass_to_kegg_dict.items()}\n",
    "mass_to_kegg_dict = {mass: kegg_ids for mass, kegg_ids in mass_to_kegg_dict.items() if kegg_ids}\n",
    "\n",
    "# Generate the mass_to_hmdb dict from the hmdb database:\n",
    "mass_to_hmdb_dict = {}\n",
    "\n",
    "for index, row in hmdb.iterrows():\n",
    "    mass = row['monisotopic_molecular_weight']\n",
    "    hmdb_id = row['accession']\n",
    "\n",
    "    if mass not in mass_to_hmdb_dict:\n",
    "        mass_to_hmdb_dict[mass] = []\n",
    "\n",
    "    mass_to_hmdb_dict[mass].append(hmdb_id)\n",
    "\n",
    "mass_to_hmdb_dict = {mass: [hmdb_id for hmdb_id in hmdb_ids if pd.notna(hmdb_id)]\n",
    "                    for mass, hmdb_ids in mass_to_hmdb_dict.items()}\n",
    "mass_to_hmdb_dict = {mass: hmdb_ids for mass, hmdb_ids in mass_to_hmdb_dict.items() if hmdb_ids}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e9599e",
   "metadata": {},
   "source": [
    "## Load relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "371c65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = pd.read_csv('correlation_df_JAN2024.csv',index_col = 0)\n",
    "correlation_df.columns = correlation_df.columns.astype(int)\n",
    "\n",
    "eigendf = pd.read_csv('eigendf_JAN2024.csv',index_col=0).reset_index(drop = True)\n",
    "df_modules = pd.read_csv('df_modules_JAN2024.csv',index_col=0).reset_index(drop = True)\n",
    "expression_data = pd.read_csv('All_data_normalised_21DEC2023.csv',index_col=0).T\n",
    "all_info = pd.read_csv('xcms_output.csv',index_col=0).reset_index(drop = True)\n",
    "all_adds = pd.read_csv('Adduct_df_JAN2024.csv',index_col = 0) # Adducts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e015af",
   "metadata": {},
   "source": [
    "## Prepare all feature masses from our LC-MS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "022ffbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_masses = [float(x.split('_')[-1]) for x in expression_data.index.tolist()]\n",
    "dict_type = {\n",
    "    'neg':'negative',\n",
    "    'pos':'positive',\n",
    "    'bas':'negative'\n",
    "}\n",
    "vals = [dict_type[x.split('_')[0]] for x in expression_data.index.tolist()]\n",
    "unknown_mass_dict = dict(zip(unknown_masses,zip(expression_data.index.tolist(),vals)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c8ded",
   "metadata": {},
   "source": [
    "## Match all our detected ions with compounds of same m/z in dataframe, with a ppm threshold of 5ppm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mz_to_mets = match_unknown_mz_values_with_metabolite_ids(unknown_mass_dict,mass_to_hmdb_dict,all_adds,hmdb_dict,ppm_threshold=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f31f9d",
   "metadata": {},
   "source": [
    "## Remove communities (modules) that do not have any putative annotation. Also, find the representative features for all modules (Protonated/Deprotonated parent ions, hydrated/dehydrated parent ions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c1138e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module 27\n",
      "3\n",
      "['bas_mz_119.0348069' '2-Ketobutyric acid']\n",
      "Module 5\n",
      "0\n",
      "['neg_mz_208.0612357' '5-Hydroxyindoleacetic acid']\n",
      "Module 8\n",
      "1\n",
      "['neg_mz_148.0425231' 'L-Methionine']\n",
      "Module 15\n",
      "1\n",
      "['neg_mz_349.2728414' 'Adrenic acid']\n",
      "Module 0\n",
      "0\n",
      "['neg_mz_163.039203' 'Phenylpyruvic acid']\n",
      "Module 23\n",
      "0\n",
      "['neg_mz_185.0919051' 'Pyridoxamine']\n",
      "Module 11\n",
      "2\n",
      "['neg_mz_367.1575865' 'Dehydroepiandrosterone sulfate']\n",
      "Module 10\n",
      "0\n",
      "['pos_mz_166.0860973' 'L-Phenylalanine']\n",
      "Module 20\n",
      "1\n",
      "['bas_mz_194.9456989' 'Pyrophosphate']\n",
      "Module 9\n",
      "0\n",
      "['pos_mz_147.0438912' 'Phenylpyruvic acid']\n",
      "Module 40\n",
      "5\n",
      "['pos_mz_120.0656837' 'L-Threonine']\n",
      "Module 63\n",
      "0\n",
      "['bas_mz_263.1019867' 'Acetyl-N-formyl-5-methoxykynurenamine']\n",
      "Module 6\n",
      "0\n",
      "['neg_mz_221.0589364' 'L-Cystathionine']\n",
      "Module 7\n",
      "0\n",
      "['pos_mz_527.158164' 'Raffinose']\n",
      "Module 68\n",
      "1\n",
      "['pos_mz_152.0705369' 'Norepinephrine']\n",
      "Module 13\n",
      "4\n",
      "['bas_mz_283.2627966' 'Stearic acid']\n",
      "Module 14\n",
      "None of the specified values were found in the specified column.\n",
      "Module 17\n",
      "1\n",
      "['neg_mz_367.1572477' 'Dehydroepiandrosterone sulfate']\n",
      "Module 72\n",
      "1\n",
      "['pos_mz_591.3174449' 'Urobilinogen']\n",
      "Module 4\n",
      "None of the specified values were found in the specified column.\n",
      "Module 75\n",
      "0\n",
      "['bas_mz_431.3152895' '3β,7α-Dihydroxy-5-cholestenoate']\n",
      "Module 49\n",
      "0\n",
      "['neg_mz_462.1756792' 'Tetrahydrofolic acid']\n",
      "Module 19\n",
      "None of the specified values were found in the specified column.\n",
      "Module 83\n",
      "None of the specified values were found in the specified column.\n",
      "Module 26\n",
      "1\n",
      "['neg_mz_111.0193693' 'Uracil']\n",
      "Module 1\n",
      "None of the specified values were found in the specified column.\n",
      "Module 82\n",
      "0\n",
      "['bas_mz_152.0342476' '3-Hydroxyanthranilic acid']\n",
      "Module 22\n",
      "None of the specified values were found in the specified column.\n",
      "Module 39\n",
      "0\n",
      "['pos_mz_128.1069017' '4-Trimethylammoniobutanoic acid']\n",
      "Module 79\n",
      "None of the specified values were found in the specified column.\n",
      "Module 65\n",
      "0\n",
      "['bas_mz_283.2626469' 'Stearic acid']\n",
      "Module 89\n",
      "0\n",
      "['bas_mz_265.0593251' \"Pyridoxamine 5'-phosphate\"]\n",
      "Module 2\n",
      "None of the specified values were found in the specified column.\n",
      "Module 24\n",
      "0\n",
      "['neg_mz_378.2393021' 'Sphingosine 1-phosphate']\n",
      "Module 34\n",
      "None of the specified values were found in the specified column.\n",
      "Module 36\n",
      "0\n",
      "['pos_mz_130.0866381' 'L-Pipecolic acid']\n",
      "Module 44\n",
      "2\n",
      "['pos_mz_118.0863354' 'L-Valine']\n",
      "Module 48\n",
      "4\n",
      "['pos_mz_843.5188545' 'PG(18:1(11Z)/22:6(4Z,7Z,10Z,13Z,16Z,19Z))']\n",
      "Module 60\n",
      "None of the specified values were found in the specified column.\n",
      "Module 29\n",
      "None of the specified values were found in the specified column.\n",
      "Module 84\n",
      "None of the specified values were found in the specified column.\n",
      "Module 41\n",
      "0\n",
      "['pos_mz_288.1031745' 'Thiamine']\n",
      "Module 47\n",
      "None of the specified values were found in the specified column.\n",
      "Module 18\n",
      "None of the specified values were found in the specified column.\n",
      "Module 37\n",
      "1\n",
      "['pos_mz_132.0654615' '4-Hydroxyproline']\n",
      "Module 30\n",
      "0\n",
      "['pos_mz_147.076503' 'L-Glutamine']\n",
      "Module 3\n",
      "0\n",
      "['bas_mz_179.0553262' 'D-Glucose']\n",
      "Module 81\n",
      "None of the specified values were found in the specified column.\n",
      "Module 12\n",
      "0\n",
      "['neg_mz_385.1669296' 'Dehydroepiandrosterone sulfate']\n",
      "Module 61\n",
      "0\n",
      "['neg_mz_514.2814198' 'Taurocholic acid']\n",
      "Module 25\n",
      "None of the specified values were found in the specified column.\n",
      "Module 80\n",
      "None of the specified values were found in the specified column.\n",
      "Module 21\n",
      "0\n",
      "['neg_mz_303.2309157' 'Arachidonic acid']\n",
      "Module 66\n",
      "1\n",
      "['bas_mz_151.0243094' 'L-Malic acid']\n",
      "Module 73\n",
      "None of the specified values were found in the specified column.\n",
      "Module 53\n",
      "None of the specified values were found in the specified column.\n",
      "Module 67\n",
      "0\n",
      "['bas_mz_255.231279' 'Palmitic acid']\n",
      "Module 85\n",
      "None of the specified values were found in the specified column.\n",
      "Module 90\n",
      "None of the specified values were found in the specified column.\n",
      "Module 16\n",
      "0\n",
      "['bas_mz_464.2991698' 'Glycocholic acid']\n",
      "Module 70\n",
      "None of the specified values were found in the specified column.\n",
      "Module 42\n",
      "0\n",
      "['pos_mz_146.1174693' '4-Trimethylammoniobutanoic acid']\n",
      "Module 28\n",
      "0\n",
      "['pos_mz_395.156543' 'Riboflavin']\n",
      "Module 38\n",
      "0\n",
      "['pos_mz_132.0654238' '4-Hydroxyproline']\n",
      "Module 50\n",
      "0\n",
      "['pos_mz_159.092494' 'Serotonin']\n",
      "Module 52\n",
      "4\n",
      "['pos_mz_203.0522997' 'D-Glucose']\n",
      "Module 43\n",
      "0\n",
      "['pos_mz_98.06015776' 'L-Proline']\n",
      "Module 45\n",
      "1\n",
      "['pos_mz_348.0706805' 'Adenosine monophosphate']\n",
      "Module 69\n",
      "0\n",
      "['pos_mz_100.075745' 'L-Valine']\n",
      "Module 32\n",
      "0\n",
      "['pos_mz_243.0269632' 'Fructose 6-phosphate']\n",
      "Module 46\n",
      "None of the specified values were found in the specified column.\n",
      "Module 35\n",
      "None of the specified values were found in the specified column.\n",
      "Module 58\n",
      "None of the specified values were found in the specified column.\n",
      "Module 74\n",
      "0\n",
      "['pos_mz_133.0608824' 'Ureidopropionic acid']\n",
      "Module 57\n",
      "None of the specified values were found in the specified column.\n",
      "Module 77\n",
      "0\n",
      "['pos_mz_152.0707117' 'Norepinephrine']\n",
      "Module 31\n",
      "None of the specified values were found in the specified column.\n",
      "Module 71\n",
      "None of the specified values were found in the specified column.\n",
      "Module 33\n",
      "None of the specified values were found in the specified column.\n",
      "Module 87\n",
      "0\n",
      "['bas_mz_493.2062657' '2-Methoxyestrone 3-glucuronide']\n",
      "Module 54\n",
      "5\n",
      "['bas_mz_359.1182153' 'D-Maltose']\n",
      "Module 55\n",
      "None of the specified values were found in the specified column.\n",
      "Module 76\n",
      "None of the specified values were found in the specified column.\n",
      "Module 51\n",
      "None of the specified values were found in the specified column.\n",
      "Module 88\n",
      "3\n",
      "['bas_mz_448.3053423' 'Deoxycholic acid glycine conjugate']\n",
      "Module 62\n",
      "2\n",
      "['bas_mz_129.0305087' 'Uracil']\n",
      "Module 56\n",
      "None of the specified values were found in the specified column.\n",
      "Module 64\n",
      "0\n",
      "['bas_mz_255.2313528' 'Palmitic acid']\n",
      "Module 86\n",
      "0\n",
      "['bas_mz_225.0627733' '5-Acetylamino-6-formylamino-3-methyluracil']\n",
      "Module 78\n",
      "0\n",
      "['bas_mz_448.3056446' 'Deoxycholic acid glycine conjugate']\n",
      "Module 59\n",
      "None of the specified values were found in the specified column.\n"
     ]
    }
   ],
   "source": [
    "mod_dict,mods_remove = trim_module_dataframe_and_find_representative_features(eigendf,expression_data,correlation_df,df_modules,all_info,mz_to_mets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bab9a4",
   "metadata": {},
   "source": [
    "## Drop non-annotated communities (modules) from eigendf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7b07b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigendf = eigendf.drop(mods_remove,axis = 1)\n",
    "feature_df = expression_data.T[mod_dict.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d62248",
   "metadata": {},
   "source": [
    "## Save for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "47180bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigendf.to_csv('eigendf_trimmed_JAN2024.csv')\n",
    "feature_df.to_csv('feature_df_JAN2024.csv')\n",
    "mz_to_mets.to_csv('mz_to_mets_JAN2024.csv')\n",
    "pathbank_dat.to_csv('PathBank_data_JAN2024.csv')\n",
    "\n",
    "with open('module_to_feature_dictionary.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(mod_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc266b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
